import streamlit as st
import pandas as pd
from typing import Dict, List, Optional, Tuple
import io
from core.file_processor import FileProcessor
from core.data_validator import DataValidator


class FileUploader:
    """–ö–æ–º–ø–æ–Ω–µ–Ω—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤"""
    
    def __init__(self):
        self.file_processor = FileProcessor()
        self.data_validator = DataValidator()
        self.supported_formats = {
            '.xlsx': 'Excel —Ñ–∞–π–ª—ã',
            '.csv': 'CSV —Ñ–∞–π–ª—ã'
        }
        
    def render(self) -> Optional[Dict]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ —Ä–µ–Ω–¥–µ—Ä–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ –∑–∞–≥—Ä—É–∑–∫–∏"""
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        if 'loaded_data' in st.session_state and st.session_state.loaded_data:
            return self._render_loaded_data_status()
        
        return self._render_upload_interface()
    
    def _render_upload_interface(self) -> Optional[Dict]:
        """–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤"""
        
        st.markdown("""
        <div style="padding: 2rem; border: 2px dashed #1f77b4; border-radius: 10px; text-align: center; background: #f8f9fa;">
            <h3 style="color: #1f77b4; margin-top: 0;">üì§ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ MPStats</h3>
            <p style="color: #666; margin-bottom: 1.5rem;">
                –ü–µ—Ä–µ—Ç–∞—â–∏—Ç–µ —Ñ–∞–π–ª—ã —Å—é–¥–∞ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫—É –¥–ª—è –≤—ã–±–æ—Ä–∞
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ñ–∞–π–ª–∞—Ö
        with st.expander("üìã –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Ñ–∞–π–ª–∞–º", expanded=True):
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("""
                **üìà –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –æ—Ç—á–µ—Ç—ã:**
                - –û—Ç—á–µ—Ç –ø–æ —Ç—Ä–µ–Ω–¥–∞–º (.xlsx)
                - –û—Ç—á–µ—Ç –ø–æ —Ç–æ–≤–∞—Ä–∞–º (.csv)
                """)
                
            with col2:
                st.markdown("""
                **üìä –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ç—á–µ—Ç—ã:**
                - –û—Ç—á–µ—Ç –ø–æ –∑–∞–ø—Ä–æ—Å–∞–º (.xlsx)
                - –¶–µ–Ω–æ–≤–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è (.xlsx)
                - –û—Ç—á–µ—Ç –ø–æ –¥–Ω—è–º (.xlsx)
                """)
            
            st.markdown("""
            **üí° –ü–æ–¥—Å–∫–∞–∑–∫–∏ –ø–æ –∏–º–µ–Ω–æ–≤–∞–Ω–∏—é —Ñ–∞–π–ª–æ–≤:**
            - –§–∞–π–ª—ã —Å '—Ç—Ä–µ–Ω–¥' –∏–ª–∏ 'trend' ‚Üí –û—Ç—á–µ—Ç –ø–æ —Ç—Ä–µ–Ω–¥–∞–º
            - –§–∞–π–ª—ã —Å '–∑–∞–ø—Ä–æ—Å' –∏–ª–∏ 'queries' ‚Üí –û—Ç—á–µ—Ç –ø–æ –∑–∞–ø—Ä–æ—Å–∞–º  
            - –§–∞–π–ª—ã —Å '—Ü–µ–Ω–æ–≤' –∏–ª–∏ 'price' ‚Üí –¶–µ–Ω–æ–≤–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è
            - –§–∞–π–ª—ã —Å '–¥–Ω—è–º' –∏–ª–∏ 'days' ‚Üí –û—Ç—á–µ—Ç –ø–æ –¥–Ω—è–º
            - –§–∞–π–ª—ã .csv ‚Üí –û—Ç—á–µ—Ç –ø–æ —Ç–æ–≤–∞—Ä–∞–º
            """)
        
        # –ó–∞–≥—Ä—É–∑—á–∏–∫ —Ñ–∞–π–ª–æ–≤
        uploaded_files = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª—ã –æ—Ç—á–µ—Ç–æ–≤ MPStats",
            type=['xlsx', 'csv'],
            accept_multiple_files=True,
            help="–ú–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ"
        )
        
        if uploaded_files:
            return self._process_uploaded_files(uploaded_files)
        
        # –ü—Ä–∏–º–µ—Ä –∑–∞–≥—Ä—É–∑–∫–∏ (–µ—Å–ª–∏ –Ω–µ—Ç —Ñ–∞–π–ª–æ–≤)
        self._render_sample_data_option()
        
        return None
    
    def _process_uploaded_files(self, uploaded_files: List) -> Optional[Dict]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        
        with st.spinner("üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤..."):
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö
            st.subheader("üìÅ –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã")
            
            files_info = []
            for file in uploaded_files:
                file_size = len(file.getvalue()) / 1024 / 1024  # MB
                files_info.append({
                    "–ù–∞–∑–≤–∞–Ω–∏–µ": file.name,
                    "–†–∞–∑–º–µ—Ä": f"{file_size:.2f} MB",
                    "–¢–∏–ø": file.type if file.type else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
                })
            
            st.dataframe(pd.DataFrame(files_info), use_container_width=True)
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤
            try:
                loaded_data = self.file_processor.process_uploaded_files(uploaded_files)
                
                if not loaded_data:
                    st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö.")
                    return None
                
                # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
                st.subheader("üîç –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö")
                validation_results = self.data_validator.validate_all_data(loaded_data)
                
                # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
                self._display_validation_results(validation_results)
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ session_state
                st.session_state.loaded_data = loaded_data
                st.session_state.file_info = self.file_processor.get_file_info()
                st.session_state.validation_results = validation_results
                
                # –£—Å–ø–µ—à–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞
                st.success("‚úÖ –§–∞–π–ª—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã!")
                
                # –ö–Ω–æ–ø–∫–∞ –ø–µ—Ä–µ—Ö–æ–¥–∞ –∫ –∞–Ω–∞–ª–∏–∑—É
                if st.button("üöÄ –ù–∞—á–∞—Ç—å –∞–Ω–∞–ª–∏–∑", type="primary", use_container_width=True):
                    st.switch_page("–ò—Ç–æ–≥–æ–≤—ã–π —Å–∫–æ—Ä–∏–Ω–≥")
                
                return loaded_data
                
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–æ–≤: {str(e)}")
                return None
    
    def _display_validation_results(self, validation_results: Dict):
        """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_files = len(validation_results)
        valid_files = sum(1 for result in validation_results.values() if result.get("valid", False))
        total_errors = sum(len(result.get("errors", [])) for result in validation_results.values())
        total_warnings = sum(len(result.get("warnings", [])) for result in validation_results.values())
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("–§–∞–π–ª–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω–æ", total_files)
        
        with col2:
            st.metric("–§–∞–π–ª–æ–≤ –≤–∞–ª–∏–¥–Ω–æ", valid_files, delta=valid_files - total_files if valid_files != total_files else None)
        
        with col3:
            color = "normal" if total_errors == 0 else "inverse"
            st.metric("–û—à–∏–±–æ–∫", total_errors, delta_color=color)
        
        with col4:
            color = "normal" if total_warnings == 0 else "off"  
            st.metric("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π", total_warnings, delta_color=color)
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if total_errors > 0 or total_warnings > 0:
            with st.expander("üìã –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏"):
                for file_type, result in validation_results.items():
                    
                    status_icon = "‚úÖ" if result.get("valid", False) else "‚ùå"
                    st.markdown(f"**{status_icon} {file_type.title()}**")
                    
                    # –û—à–∏–±–∫–∏
                    if result.get("errors"):
                        for error in result["errors"]:
                            st.error(f"‚Ä¢ {error}")
                    
                    # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
                    if result.get("warnings"):
                        for warning in result["warnings"]:
                            st.warning(f"‚Ä¢ {warning}")
                    
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                    if "records_count" in result:
                        st.info(f"üìä –ó–∞–ø–∏—Å–µ–π: {result['records_count']}")
                    
                    st.markdown("---")
    
    def _render_loaded_data_status(self) -> Dict:
        """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        
        st.success("‚úÖ –î–∞–Ω–Ω—ã–µ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
        
        loaded_data = st.session_state.loaded_data
        file_info = st.session_state.get('file_info', {})
        
        # –°–≤–æ–¥–∫–∞ –ø–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º —Ñ–∞–π–ª–∞–º
        st.subheader("üìä –°–≤–æ–¥–∫–∞ –ø–æ –¥–∞–Ω–Ω—ã–º")
        
        summary_data = []
        for data_type, data in loaded_data.items():
            info = file_info.get(data_type, {})
            summary_data.append({
                "–¢–∏–ø –æ—Ç—á–µ—Ç–∞": data_type.title(),
                "–§–∞–π–ª": info.get("filename", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"),
                "–ó–∞–ø–∏—Å–µ–π": len(data),
                "–ö–æ–ª–æ–Ω–æ–∫": len(data.columns),
                "–°—Ç–∞—Ç—É—Å": "‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω"
            })
        
        st.dataframe(pd.DataFrame(summary_data), use_container_width=True)
        
        # –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö
        self._render_data_preview(loaded_data)
        
        # –î–µ–π—Å—Ç–≤–∏—è —Å –¥–∞–Ω–Ω—ã–º–∏
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üîÑ –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª—ã", use_container_width=True):
                self._clear_loaded_data()
                st.rerun()
        
        with col2:
            if st.button("üìä –û—Ç–∫—Ä—ã—Ç—å –∞–Ω–∞–ª–∏–∑", use_container_width=True, type="primary"):
                st.switch_page("–ò—Ç–æ–≥–æ–≤—ã–π —Å–∫–æ—Ä–∏–Ω–≥")
        
        with col3:
            if st.button("üìã –ü–æ–∫–∞–∑–∞—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—é", use_container_width=True):
                if 'validation_results' in st.session_state:
                    self._display_validation_results(st.session_state.validation_results)
        
        return loaded_data
    
    def _render_data_preview(self, loaded_data: Dict):
        """–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        
        st.subheader("üëÅÔ∏è –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö")
        
        # –í—ã–±–æ—Ä —Ç–∏–ø–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞
        data_types = list(loaded_data.keys())
        selected_type = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞:", data_types)
        
        if selected_type and selected_type in loaded_data:
            data = loaded_data[selected_type]
            
            # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("–°—Ç—Ä–æ–∫", len(data))
            
            with col2:
                st.metric("–ö–æ–ª–æ–Ω–æ–∫", len(data.columns))
            
            with col3:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö
                date_columns = [col for col in data.columns if any(word in col.lower() for word in ['–¥–∞—Ç–∞', '–º–µ—Å—è—Ü', 'date'])]
                if date_columns:
                    try:
                        date_col = date_columns[0]
                        date_range = pd.to_datetime(data[date_col])
                        period = f"{date_range.min().strftime('%Y-%m')} ‚Äî {date_range.max().strftime('%Y-%m')}"
                        st.metric("–ü–µ—Ä–∏–æ–¥", period)
                    except:
                        st.metric("–ü–µ—Ä–∏–æ–¥", "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω")
                else:
                    st.metric("–ü–µ—Ä–∏–æ–¥", "–ù–µ –ø—Ä–∏–º–µ–Ω–∏–º–æ")
            
            # –¢–∞–±–ª–∏—Ü–∞ —Å –¥–∞–Ω–Ω—ã–º–∏
            st.markdown("**–ü–µ—Ä–≤—ã–µ 10 –∑–∞–ø–∏—Å–µ–π:**")
            st.dataframe(data.head(10), use_container_width=True)
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–ª–æ–Ω–∫–∞—Ö
            with st.expander("üìã –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–ª–æ–Ω–∫–∞—Ö"):
                column_info = []
                for col in data.columns:
                    non_null_count = data[col].count()
                    null_count = len(data) - non_null_count
                    dtype = str(data[col].dtype)
                    
                    column_info.append({
                        "–ö–æ–ª–æ–Ω–∫–∞": col,
                        "–¢–∏–ø –¥–∞–Ω–Ω—ã—Ö": dtype,
                        "–ó–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö": non_null_count,
                        "–ü—É—Å—Ç—ã—Ö": null_count,
                        "% –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç–∏": f"{(non_null_count/len(data)*100):.1f}%"
                    })
                
                st.dataframe(pd.DataFrame(column_info), use_container_width=True)
    
    def _render_sample_data_option(self):
        """–û–ø—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–∏–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö"""
        
        st.markdown("---")
        
        with st.expander("üéØ –ù–µ—Ç —Ñ–∞–π–ª–æ–≤? –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å –ø—Ä–∏–º–µ—Ä–æ–º –¥–∞–Ω–Ω—ã—Ö"):
            st.markdown("""
            –ï—Å–ª–∏ —É –≤–∞—Å –Ω–µ—Ç —Ñ–∞–π–ª–æ–≤ MPStats, –≤—ã –º–æ–∂–µ—Ç–µ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –ø—Ä–∏–º–µ—Ä–æ–º –¥–∞–Ω–Ω—ã—Ö 
            –¥–ª—è –æ–∑–Ω–∞–∫–æ–º–ª–µ–Ω–∏—è —Å —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–æ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞.
            """)
            
            if st.button("üìä –ó–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö", use_container_width=True):
                self._load_sample_data()
    
    def _load_sample_data(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–∏–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö"""
        
        with st.spinner("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–∏–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö..."):
            try:
                # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
                sample_data = self._generate_sample_data()
                
                # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–∏–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
                validation_results = self.data_validator.validate_all_data(sample_data)
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ session_state
                st.session_state.loaded_data = sample_data
                st.session_state.file_info = {
                    "trends": {"filename": "sample_trends.xlsx", "rows": len(sample_data["trends"]), "columns": len(sample_data["trends"].columns)},
                    "products": {"filename": "sample_products.csv", "rows": len(sample_data["products"]), "columns": len(sample_data["products"].columns)}
                }
                st.session_state.validation_results = validation_results
                
                st.success("‚úÖ –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –∑–∞–≥—Ä—É–∂–µ–Ω!")
                st.info("üí° –≠—Ç–æ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–∑–Ω–∞–∫–æ–º–ª–µ–Ω–∏—è —Å —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–æ–º")
                
                st.rerun()
                
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø—Ä–∏–º–µ—Ä–∞: {str(e)}")
    
    def _generate_sample_data(self) -> Dict:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö"""
        
        # –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤
        import numpy as np
        from datetime import datetime, timedelta
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞—Ç—ã –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 12 –º–µ—Å—è—Ü–µ–≤
        end_date = datetime.now()
        dates = [end_date - timedelta(days=30*i) for i in range(12)][::-1]
        
        trends_data = pd.DataFrame({
            '–ú–µ—Å—è—Ü': dates,
            '–ü—Ä–æ–¥–∞–∂–∏': np.random.randint(1000, 5000, 12),
            '–í—ã—Ä—É—á–∫–∞, ‚ÇΩ': np.random.randint(500000, 2000000, 12),
            '–¢–æ–≤–∞—Ä—ã': np.random.randint(100, 300, 12),
            '–¢–æ–≤–∞—Ä—ã —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏': np.random.randint(50, 150, 12),
            '–ë—Ä–µ–Ω–¥—ã': np.random.randint(20, 50, 12),
            '–ë—Ä–µ–Ω–¥—ã —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏': np.random.randint(15, 35, 12),
            '–ü—Ä–æ–¥–∞–≤—Ü—ã': np.random.randint(30, 80, 12),
            '–ü—Ä–æ–¥–∞–≤—Ü—ã —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏': np.random.randint(20, 60, 12),
            '–°—Ä–µ–¥–Ω–∏–π —á–µ–∫, ‚ÇΩ': np.random.randint(800, 1500, 12)
        })
        
        # –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
        products_data = pd.DataFrame({
            'SKU': range(1000000, 1000100),
            'Name': [f'–¢–µ—Å—Ç–æ–≤—ã–π —Ç–æ–≤–∞—Ä {i}' for i in range(100)],
            'Category': ['–¢–µ—Å—Ç–æ–≤–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è'] * 100,
            'Brand': [f'–ë—Ä–µ–Ω–¥ {i%10}' for i in range(100)],
            'Final price': np.random.randint(500, 3000, 100),
            'Sales': np.random.randint(0, 1000, 100),
            'Revenue': np.random.randint(0, 500000, 100),
            'Category position avg': np.random.randint(1, 200, 100),
            'Search cpm avg': np.random.randint(50, 800, 100),
            'Search words in ads': np.random.randint(0, 50, 100),
            'Search organic position avg': np.random.randint(1, 300, 100)
        })
        
        return {
            'trends': trends_data,
            'products': products_data
        }
    
    def _clear_loaded_data(self):
        """–û—á–∏—Å—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        keys_to_clear = ['loaded_data', 'file_info', 'validation_results', 'analysis_results', 'scoring_results']
        
        for key in keys_to_clear:
            if key in st.session_state:
                del st.session_state[key]
    
    def get_upload_requirements(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∫ –∑–∞–≥—Ä—É–∂–∞–µ–º—ã–º —Ñ–∞–π–ª–∞–º"""
        return {
            "trends": {
                "name": "–û—Ç—á–µ—Ç –ø–æ —Ç—Ä–µ–Ω–¥–∞–º",
                "format": ".xlsx",
                "required_columns": ["–ú–µ—Å—è—Ü", "–ü—Ä–æ–¥–∞–∂–∏", "–í—ã—Ä—É—á–∫–∞, ‚ÇΩ", "–¢–æ–≤–∞—Ä—ã", "–ë—Ä–µ–Ω–¥—ã"],
                "description": "–î–∏–Ω–∞–º–∏–∫–∞ –ø—Ä–æ–¥–∞–∂ –∏ –æ—Å–Ω–æ–≤–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –ø–æ –º–µ—Å—è—Ü–∞–º"
            },
            "queries": {
                "name": "–û—Ç—á–µ—Ç –ø–æ –∑–∞–ø—Ä–æ—Å–∞–º", 
                "format": ".xlsx",
                "required_columns": ["–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ", "–ß–∞—Å—Ç–æ—Ç–∞ WB", "–¢–æ–≤–∞—Ä–æ–≤ –≤ –∑–∞–ø—Ä–æ—Å–µ"],
                "description": "–ü–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –∏ –∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏"
            },
            "price": {
                "name": "–¶–µ–Ω–æ–≤–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è",
                "format": ".xlsx", 
                "required_columns": ["–û—Ç", "–î–æ", "–í—ã—Ä—É—á–∫–∞ –Ω–∞ —Ç–æ–≤–∞—Ä, ‚ÇΩ", "–¢–æ–≤–∞—Ä—ã", "–ü—Ä–æ–¥–∞–≤—Ü—ã"],
                "description": "–ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Ü–µ–Ω–æ–≤—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤"
            },
            "days": {
                "name": "–û—Ç—á–µ—Ç –ø–æ –¥–Ω—è–º",
                "format": ".xlsx",
                "required_columns": ["–î–∞—Ç–∞", "–û—Å—Ç–∞—Ç–æ–∫", "–ü—Ä–æ–¥–∞–∂–∏, —à—Ç.", "–í—ã—Ä—É—á–∫–∞, ‚ÇΩ"],
                "description": "–ï–∂–µ–¥–Ω–µ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤ –∏ –ø—Ä–æ–¥–∞–∂"
            },
            "products": {
                "name": "–û—Ç—á–µ—Ç –ø–æ —Ç–æ–≤–∞—Ä–∞–º",
                "format": ".csv",
                "required_columns": ["SKU", "Final price", "Category position avg", "Search cmp avg"],
                "description": "–î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–æ–≤–∞—Ä–∞—Ö –∏ –∏—Ö –ø–æ–∑–∏—Ü–∏—è—Ö"
            }
        }
    
    def validate_file_structure(self, file_type: str, data: pd.DataFrame) -> Tuple[bool, List[str]]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
        requirements = self.get_upload_requirements()
        
        if file_type not in requirements:
            return False, [f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞: {file_type}"]
        
        required_columns = requirements[file_type]["required_columns"]
        missing_columns = [col for col in required_columns if col not in data.columns]
        
        if missing_columns:
            return False, [f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {', '.join(missing_columns)}"]
        
        return True, []
